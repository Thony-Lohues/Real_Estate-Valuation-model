{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from math import *\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.common.exceptions import TimeoutException"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scrap Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Bot:\n",
    "\n",
    "    def ScrapHouses(self, MaxRetrieves):\n",
    "\n",
    "        URL_1 = 'https://www.century21global.com/for-sale-residential/USA/NY/New-York-Metro-Area?pageNo='\n",
    "        page = 1\n",
    "        pageIncrement = 20\n",
    "        maxRetrieves = MaxRetrieves\n",
    "        Wait = 30\n",
    "        Houses = []\n",
    "        House_infos = []\n",
    "\n",
    "        url = URL_1 + str(page)\n",
    "\n",
    "        options = Options()\n",
    "        options.headless = True   # Do we want to see the website ? True = no; False = yes\n",
    "        options.add_experimental_option(\"detach\", True)\n",
    "\n",
    "        browser = webdriver.Chrome(ChromeDriverManager().install(), options=options)\n",
    "        browser.maximize_window()\n",
    "        browser.get(url)\n",
    "        browser.set_page_load_timeout(Wait)\n",
    "\n",
    "        Houses_to_scrap_string = browser.find_element_by_xpath('//*[@id=\"propertySearchResults\"]/div[1]/div/div[2]/span[2]')\n",
    "        Houses_to_scrap = int(Houses_to_scrap_string.text.replace('(', '').replace(')','').replace(' ','').replace(',',''))\n",
    "\n",
    "        nb = 1\n",
    "        count = 1\n",
    "\n",
    "\n",
    "        while True :\n",
    "\n",
    "            try :\n",
    "                if nb > min(maxRetrieves,Houses_to_scrap) :\n",
    "                    break\n",
    "\n",
    "                if count > pageIncrement :\n",
    "                    count = 1\n",
    "                    page += 1\n",
    "\n",
    "                url = URL_1 + str(page)\n",
    "                browser.get(url)\n",
    "                browser.set_page_load_timeout(Wait)\n",
    "\n",
    "                house = browser.find_element_by_xpath('//*[@id=\"propertySearchResults\"]/div[' + str(count+2) + ']')\n",
    "                house.click()\n",
    "                browser.set_page_load_timeout(Wait)\n",
    "\n",
    "                # Get houses information\n",
    "\n",
    "                price = browser.find_element_by_xpath('//*[@id=\"listingDetails\"]/div[2]/div/div/h2').text\n",
    "\n",
    "                location = browser.find_element_by_xpath('//*[@id=\"listingDetails\"]/div[2]/div/div/div[2]').text.replace('\\n',' /;/ ')\n",
    "\n",
    "                details_1 = []\n",
    "                details_2 = []\n",
    "\n",
    "                d_1 = browser.find_element_by_xpath('//*[@id=\"listingDetails\"]/div[2]/div/div/div[5]')\n",
    "                for x in d_1.find_elements_by_tag_name('div') :\n",
    "                    if x.text != '' :\n",
    "                        details_1.append(x.text)\n",
    "\n",
    "\n",
    "                d_2 = browser.find_element_by_xpath('//*[@id=\"listingDetails\"]/div[2]/div/div/ul')\n",
    "                for x in d_2.find_elements_by_tag_name('li') :\n",
    "                    if x.text != '' :\n",
    "                        details_2.append(x.text)\n",
    "\n",
    "                House_infos = {\n",
    "                    'Price' : price,\n",
    "                    'Location' : location,\n",
    "                    'Caracteristics_1' : details_1,\n",
    "                    'Caracteristics_2' : details_2\n",
    "                }\n",
    "\n",
    "                Houses.append(House_infos)\n",
    "\n",
    "                url = URL_1 + str(page)\n",
    "                browser.get(url)\n",
    "                browser.set_page_load_timeout(Wait)\n",
    "\n",
    "                count += 1\n",
    "\n",
    "                print(str(nb) + '/' + str(min(Houses_to_scrap,maxRetrieves)))\n",
    "                nb += 1\n",
    "            \n",
    "            except Exception as e :\n",
    "                \n",
    "                try :\n",
    "\n",
    "                    print(\"Exception\",e)\n",
    "\n",
    "                    url = URL_1 + str(page)\n",
    "                    browser.get(url)\n",
    "                    browser.set_page_load_timeout(Wait)\n",
    "\n",
    "                    count += 1\n",
    "\n",
    "                    print(str(nb) + '/' + str(min(Houses_to_scrap,maxRetrieves)))\n",
    "                    nb += 1\n",
    "\n",
    "                except Exception as e :\n",
    "\n",
    "                    print(\"Exception\",e)\n",
    "                    break\n",
    "\n",
    "        return Houses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Scrapper = Bot()\n",
    "Results = Scrapper.ScrapHouses(10000)\n",
    "DF = pd.DataFrame(Results)\n",
    "DF.to_excel(r'C:\\Users\\lohue\\Desktop\\Real_Estate Valuation model\\Outputs_NYC.xlsx', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "NY = pd.read_excel('Outputs_NYC.xlsx').dropna()\n",
    "\n",
    "def search_string(DF,column_,search_sing, search_plurial) :\n",
    "\n",
    "    x = []\n",
    "\n",
    "    for i in range(0, len(DF)):\n",
    "            if DF[column_][i].find(search_sing) == -1 and DF[column_][i].find(search_plurial) == -1:\n",
    "                x.append('na')\n",
    "            else:\n",
    "                if DF[column_][i].find(search_sing) != -1 :\n",
    "                    j = 3\n",
    "                    while DF[column_][i][DF[column_][i].find(search_sing)-j] != \"'\" and DF[column_][i][DF[column_][i].find(search_sing)-j] != '\"':\n",
    "                        j = j+1\n",
    "                    x.append(DF[column_][i][DF[column_][i].find(search_sing)-j+1:DF[column_][i].find(search_sing)-1])\n",
    "                else :\n",
    "                    j = 3\n",
    "                    while DF[column_][i][DF[column_][i].find(search_plurial)-j] != \"'\" and DF[column_][i][DF[column_][i].find(search_plurial)-j] != '\"':\n",
    "                        j = j+1\n",
    "                    x.append(DF[column_][i][DF[column_][i].find(search_plurial)-j+1:DF[column_][i].find(search_plurial)-1])\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "def Construction_year(DF, column_) :\n",
    "\n",
    "    x = []\n",
    "\n",
    "    for i in range(0, len(DF)):\n",
    "        if DF[column_][i].find(\"Year Built:\") != -1 :\n",
    "            j = len(\"Year Built:\")+1\n",
    "            while DF[column_][i][DF[column_][i].find(\"Year Built:\")+j] != \"'\" :\n",
    "                j += 1\n",
    "            x.append(int(DF[column_][i][DF[column_][i].find(\"Year Built:\")+len(\"Year Built:\")+1:DF[column_][i].find(\"Year Built:\")+j]))\n",
    "        elif DF[column_][i].find(\"New Construction\") != -1 :\n",
    "            x.append(2021)\n",
    "        else :\n",
    "            x.append('na')\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "\n",
    "def Data_cleaning(DF, city) :\n",
    "\n",
    "    DF.insert(1, \"Currency\", DF['Price'].str[-3:], True)\n",
    "    DF['Price'] = pd.to_numeric(DF['Price'].str.replace(DF['Price'][0][-4:], '').str.replace('$','').str.replace(' ','').str.replace(',',''))\n",
    "    DF['Location'], DF['Ville']  = DF['Location'].str.split('/;/', 1).str\n",
    "    DF['Location'] = DF['Location'].str.replace(', '+ city,'')\n",
    "    DF['Ville'], DF['Pays'] = DF['Ville'].str.split('/;/', 1).str\n",
    "    for i in range(0, len(DF)):\n",
    "        if DF['Ville'][i].find(',') == -1:\n",
    "            DF['Ville'][i] = DF['Ville'][i][0:-6]\n",
    "        else :\n",
    "            DF['Ville'][i] = DF['Ville'][i][0:DF['Ville'][i].find(',')]\n",
    "        \n",
    "    DF = DF.drop(['Location'],axis = 1)\n",
    "    DF['Bedrooms'] = search_string(DF,'Caracteristics_1','bedroom', 'bedrooms')\n",
    "    DF['Bathrooms'] = search_string(DF,'Caracteristics_1','full bath', 'full baths')\n",
    "    DF['Area'] = search_string(DF,'Caracteristics_1','m2', 'm2')\n",
    "    DF['Area'] = DF['Area'].str.replace('.','')\n",
    "    DF['Construction year'] = Construction_year(DF, 'Caracteristics_2')\n",
    "\n",
    "    DF = DF.drop(DF[DF['Ville'] == 'na'].index | DF[DF['Bedrooms'] == 'na'].index | DF[DF['Bathrooms'] == 'na'].index | DF[DF['Area'] == 'na'].index | DF[DF['Construction year'] == 'na'].index).reset_index()\n",
    "\n",
    "    DF['Bedrooms'] = pd.to_numeric(\n",
    "        DF['Bedrooms'], \n",
    "        errors='coerce'\n",
    "        ).fillna(0).astype('int')\n",
    "\n",
    "    DF['Bathrooms'] = pd.to_numeric(\n",
    "        DF['Bathrooms'], \n",
    "        errors='coerce'\n",
    "        ).fillna(0).astype('int')\n",
    "\n",
    "    DF['Area'] = pd.to_numeric(\n",
    "        DF['Area'], \n",
    "        errors='coerce'\n",
    "        ).fillna(0).astype('int')\n",
    "\n",
    "    DF['Construction year'] = pd.to_numeric(\n",
    "        DF['Construction year'], \n",
    "        errors='coerce'\n",
    "        ).fillna(0).astype('int')\n",
    "\n",
    "    return DF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lohue\\AppData\\Local\\Programs\\Python\\Python37-32\\lib\\site-packages\\ipykernel_launcher.py:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\lohue\\AppData\\Local\\Programs\\Python\\Python37-32\\lib\\site-packages\\ipykernel_launcher.py:55: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "NY = pd.read_excel('Outputs_NYC.xlsx').dropna()\n",
    "\n",
    "\n",
    "df = Data_cleaning(NY, 'New York')\n",
    "df.to_excel(r'C:\\Users\\lohue\\Desktop\\Real_Estate Valuation model\\Outputs_clean.xlsx', index = False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Price</th>\n",
       "      <th>Bedrooms</th>\n",
       "      <th>Bathrooms</th>\n",
       "      <th>Area</th>\n",
       "      <th>Construction year</th>\n",
       "      <th>NY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>7395000</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>237174</td>\n",
       "      <td>2021</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>6100000</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>246649</td>\n",
       "      <td>2021</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>5900000</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>225004</td>\n",
       "      <td>2021</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>5250000</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>210233</td>\n",
       "      <td>2021</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>3990000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>155886</td>\n",
       "      <td>2021</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>3799999</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>318833</td>\n",
       "      <td>1930</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>3710000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>15858</td>\n",
       "      <td>2021</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>3690000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>155515</td>\n",
       "      <td>2021</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>3595000</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>151427</td>\n",
       "      <td>2021</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>3495000</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>151427</td>\n",
       "      <td>2021</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Price  Bedrooms  Bathrooms    Area  Construction year  NY\n",
       "0  7395000         4          4  237174               2021   1\n",
       "1  6100000         4          4  246649               2021   1\n",
       "2  5900000         3          3  225004               2021   1\n",
       "3  5250000         3          3  210233               2021   1\n",
       "4  3990000         2          2  155886               2021   1\n",
       "5  3799999         5          4  318833               1930   0\n",
       "6  3710000         2          2   15858               2021   1\n",
       "7  3690000         2          2  155515               2021   1\n",
       "8  3595000         3          3  151427               2021   1\n",
       "9  3495000         3          3  151427               2021   1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NY_dummy = []\n",
    "for i in range(0, len(df.Ville)):\n",
    "    if df.Ville[i] == ' New York ' :\n",
    "        NY_dummy.append(1)\n",
    "    else :\n",
    "        NY_dummy.append(0)\n",
    "\n",
    "df['NY'] = NY_dummy\n",
    "\n",
    "#Let's select some features that we want to use for regression.\n",
    "\n",
    "cdf = df[['Price','Bedrooms','Bathrooms','Area','Construction year','NY']]\n",
    "\n",
    "# Let's split the data into 2 samples \n",
    "\n",
    "msk = np.random.rand(len(df)) < 0.8\n",
    "train = cdf[msk]\n",
    "test = cdf[~msk]\n",
    "\n",
    "cdf.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients:  [[1.16784503e+04 2.58333560e+05 3.00499752e-01 8.32586787e+02\n",
      "  2.94351428e+06]]\n"
     ]
    }
   ],
   "source": [
    "# Multiple Regression Model\n",
    "\n",
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "regr = linear_model.LinearRegression()\n",
    "\n",
    "x = np.asanyarray(train[['Bedrooms','Bathrooms','Area','Construction year','NY']])\n",
    "y = np.asanyarray(train[['Price']])\n",
    "regr.fit (x, y)\n",
    "# The coefficients\n",
    "print ('Coefficients: ', regr.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Residual sum of squares: 189723742040.35\n",
      "Variance score: 0.71\n"
     ]
    }
   ],
   "source": [
    "# Prediction\n",
    "\n",
    "\n",
    "y_hat= regr.predict(test[['Bedrooms','Bathrooms','Area','Construction year','NY']])\n",
    "x = np.asanyarray(test[['Bedrooms','Bathrooms','Area','Construction year','NY']])\n",
    "y = np.asanyarray(test[['Price']])\n",
    "print(\"Residual sum of squares: %.2f\"\n",
    "      % np.mean((y_hat - y) ** 2))\n",
    "\n",
    "# Explained variance score: 1 is perfect prediction\n",
    "print('Variance score: %.2f' % regr.score(x, y))\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5891ab0d2de06d6c55b6a27c532b350d23012d0831662e3bb70ad4d754921d14"
  },
  "kernelspec": {
   "display_name": "Python 3.7.2 32-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
